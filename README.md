# âœ‹Gestura: AI-Powered Sign Language Translation ğŸ¤–
ğŸš€**Gestura** is an AI-powered real-time translator that converts hand gestures from sign language into **text** and **speech**, aiming to bridge communication gaps for the hearing and speech impaired.

Built using **Python**, **MediaPipe**, **OpenCV**, and a **Random Forest classifier**, this project brings machine learning and accessibility together in a meaningful way. .ğŸ§â€â™‚ï¸ğŸ”¤

## ğŸŒŸProject Overview
Sign language is vital for millions worldwide, but the language barrier limits its understanding among non-signers. **Gestura** addresses this issue by using computer vision and machine learning to interpret hand gestures in real time and translate them into spoken or written language.
  
## ğŸ‘¨â€ğŸ’»Features
 -âœ…Real-time sign recognition:Captures hand gestures using a webcam and processes them using MediaPipeâ€™s hand landmark detection . ğŸ“¹  
 -âœ… Landmark Extraction & Gesture Analysis: Uses hand keypoints to identify specific gesture patterns .ğŸŒ 
 -âœ… Machine learning translation: A **Random Forest model** classifies recognized gestures and maps them to corresponding text.ğŸ—£ï¸ 
 -âœ…Text-to-Speech Output: Integrates speech synthesis to voice out the translated gesture  ğŸ“¹.

## âš™ï¸ Tech Stack

- **Languages:** Python  
- **Libraries/Tools:** MediaPipe, OpenCV, Scikit-learn, NumPy, pyttsx3 / gTTS  
- **Algorithm:** Random Forest Classifier  
- **Interface:** Webcam-based CLI

## ğŸŒŸGetting Started
  1.ğŸ”§ Installation:
  ```
   #Clone the repository
   git clone https://github.com/Shristirajpoot/Gestura.git
   
   #Navigate to the project directory
   cd sign-language-detector-flask-python
  ```
  
  2. **Install the required dependencies** using the following command:

  ```bash
    pip install -r requirements.txt
  ```
   
  3. Run the application:
  ```
   python sign-language-detector-flask-python.py
  ```
   
  3. Interact with the translator :
   - Activate the camera for real-time gesture recognition.
   - Perform a supported hand gesture.
   - Watch it translate to text or hear it via text-to-speech
## ğŸŒŸScreenshotsğŸ¨ 
  ### Account Page
![Screenshot (50)](https://github.com/Shristirajpoot/Gestura/blob/main/Screenshot%202025-01-28%20105641.png)

  ### Home Page
![Screenshot (104)](https://github.com/Shristirajpoot/Gestura/blob/main/Screenshot%202025-01-30%20221835.png)
### Login Page
![Screenshot (104)](https://github.com/Shristirajpoot/Gestura/blob/main/Screenshot%202025-01-30%20221905.png)

###  ğŸ“¸Dashboard Page
![Screenshot (104)](https://github.com/Shristirajpoot/Gestura/blob/main/Screenshot%202025-01-30%20221937.png)

### Feedback Page
![Screenshot (104)](https://github.com/Shristirajpoot/Gestura/blob/main/Screenshot%202025-01-30%20222018.png)
### Tables Page
![Screenshot (104)](https://github.com/Shristirajpoot/Gestura/blob/main/Screenshot%202025-01-30%20222513.png)

  ### ğŸŒ™Camera Page
![hand-signs-of-the-ASL-Language.png](https://github.com/Shristirajpoot/Gestura/blob/main/Screenshot%202025-01-30%20224408.png)

## ğŸ¥ Demo Video

[![Watch the demo](https://img.youtube.com/vi/sVI3OwGbkoI/0.jpg)](https://www.youtube.com/watch?v=sVI3OwGbkoI)

 ## ğŸ› ï¸ What I Learned
-Implementing computer vision with MediaPipe
-Applying machine learning for gesture classification
-Building accessibility-focused real-time applications
-Understanding model training, preprocessing, and inference with live inputs
## ğŸ“œProject Report
ğŸ”“ For detailed insights, analysis, and findings, refer to the Project Report provided in the repository.
  
## ğŸ¤Contributing
ğŸ™Œ Contributions are welcome! If you'd like to contribute to this project, feel free to open issues, create pull requests, or reach out to discuss potential improvements.
